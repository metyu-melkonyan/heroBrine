{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_sequences_from_csv(filename, sequence_length=10):\n",
        "  # Load dataset\n",
        "  data = pd.read_csv(filename)  # Replace with your dataset path\n",
        "\n",
        "  # Fill missing values\n",
        "  # data['province'] = data['province'].fillna('unknown')\n",
        "  #data['city'] = data['city'].fillna('unknown')\n",
        "\n",
        "  # Encode categorical variables\n",
        "  categorical_columns = ['debit_credit']\n",
        "  for col in categorical_columns:\n",
        "      data[col] = LabelEncoder().fit_transform(data[col])\n",
        "\n",
        "  # Normalize numerical variables\n",
        "  scaler = MinMaxScaler()\n",
        "  data['amount_cad'] = scaler.fit_transform(data[['amount_cad']])\n",
        "\n",
        "  # Combine transaction_date and transaction_time into a single datetime feature\n",
        "  if 'transaction_time' in data.columns:\n",
        "    data['transaction_datetime'] = pd.to_datetime(data['transaction_date'] + ' ' + data['transaction_time'])\n",
        "    data = data.sort_values(by=['customer_id', 'transaction_datetime'])\n",
        "  else:\n",
        "    data = data.sort_values(by=['customer_id', 'transaction_date'])\n",
        "\n",
        "  # Drop unused columns\n",
        "  columns_to_keep = ['customer_id', 'amount_cad', 'debit_credit']\n",
        "  data = data[columns_to_keep]\n",
        "\n",
        "  # Group by customer_id and create sequences\n",
        "  grouped = data.groupby('customer_id')\n",
        "  sequences = []\n",
        "  for customer_id, group in grouped:\n",
        "      group = group.drop(columns=['customer_id']).values\n",
        "      for i in range(len(group) - sequence_length + 1):\n",
        "          sequences.append(group[i:i+sequence_length])\n",
        "  sequences = np.array(sequences)\n",
        "  return sequences\n"
      ],
      "metadata": {
        "id": "OVZ5fQtJWYp3"
      },
      "id": "OVZ5fQtJWYp3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "e1uWf0PVBxvNhuhevXz8YCbF",
      "metadata": {
        "tags": [],
        "id": "e1uWf0PVBxvNhuhevXz8YCbF",
        "outputId": "4e8e121e-05ce-414f-cc54-b38898d2cc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sequence_length = 10\n",
        "sequences = load_sequences_from_csv(\"abm.csv\", sequence_length)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test = train_test_split(sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# LSTM Autoencoder Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, activation='relu', input_shape=(sequence_length, X_train.shape[2]), return_sequences=True),\n",
        "    tf.keras.layers.LSTM(32, activation='relu', return_sequences=False),\n",
        "    tf.keras.layers.RepeatVector(sequence_length),\n",
        "    tf.keras.layers.LSTM(32, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.LSTM(64, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(X_train.shape[2]))\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, X_train, epochs=20, batch_size=32, validation_split=0.2, shuffle=True)\n",
        "\n",
        "# Reconstruction errors\n",
        "X_test_pred = model.predict(X_test)\n",
        "test_loss = np.mean(np.power(X_test - X_test_pred, 2), axis=(1, 2))\n",
        "\n",
        "# Anomaly detection threshold\n",
        "threshold = np.percentile(test_loss, 95)  # Adjust as needed\n",
        "anomalies = test_loss > threshold\n",
        "\n",
        "print(f\"Threshold: {threshold}\")\n",
        "print(f\"Number of anomalies detected: {np.sum(anomalies)}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m17,152\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_8 (\u001b[38;5;33mRepeatVector\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_34 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_35 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m24,832\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_8 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2\u001b[0m)               │             \u001b[38;5;34m130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,152</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,850\u001b[0m (245.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,850</span> (245.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,850\u001b[0m (245.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,850</span> (245.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[7.04247683e-04 1.00000000e+00]\n",
            "  [3.98995739e-03 1.00000000e+00]\n",
            "  [9.93139829e-03 1.00000000e+00]\n",
            "  ...\n",
            "  [8.14482228e-03 1.00000000e+00]\n",
            "  [1.00365350e-02 1.00000000e+00]\n",
            "  [1.87675600e-02 0.00000000e+00]]\n",
            "\n",
            " [[7.67516793e-03 0.00000000e+00]\n",
            "  [9.92438294e-04 1.00000000e+00]\n",
            "  [2.08496226e-04 1.00000000e+00]\n",
            "  ...\n",
            "  [1.70903299e-03 1.00000000e+00]\n",
            "  [5.95247839e-03 1.00000000e+00]\n",
            "  [9.58932978e-03 1.00000000e+00]]\n",
            "\n",
            " [[9.83271569e-03 1.00000000e+00]\n",
            "  [7.97130927e-04 1.00000000e+00]\n",
            "  [4.94535463e-03 1.00000000e+00]\n",
            "  ...\n",
            "  [6.90310519e-03 1.00000000e+00]\n",
            "  [4.94582232e-03 1.00000000e+00]\n",
            "  [4.90242068e-03 1.00000000e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1.89095507e-02 0.00000000e+00]\n",
            "  [9.94945112e-03 1.00000000e+00]\n",
            "  [4.03897130e-03 1.00000000e+00]\n",
            "  ...\n",
            "  [4.78727539e-04 1.00000000e+00]\n",
            "  [4.84162097e-03 0.00000000e+00]\n",
            "  [3.00135415e-03 1.00000000e+00]]\n",
            "\n",
            " [[9.66958540e-03 1.00000000e+00]\n",
            "  [4.80027717e-03 1.00000000e+00]\n",
            "  [3.84721838e-04 1.00000000e+00]\n",
            "  ...\n",
            "  [3.94262715e-04 1.00000000e+00]\n",
            "  [2.01696013e-03 1.00000000e+00]\n",
            "  [3.93383458e-03 1.00000000e+00]]\n",
            "\n",
            " [[1.43640711e-02 0.00000000e+00]\n",
            "  [9.60429586e-03 1.00000000e+00]\n",
            "  [5.92263976e-03 0.00000000e+00]\n",
            "  ...\n",
            "  [2.41225176e-03 1.00000000e+00]\n",
            "  [4.88361954e-04 1.00000000e+00]\n",
            "  [4.03971961e-03 0.00000000e+00]]]\n",
            "Epoch 1/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.1829 - val_loss: 0.0887\n",
            "Epoch 2/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0868 - val_loss: 0.0811\n",
            "Epoch 3/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0804 - val_loss: 0.0740\n",
            "Epoch 4/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0745 - val_loss: 0.0659\n",
            "Epoch 5/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0653 - val_loss: 0.0581\n",
            "Epoch 6/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0574 - val_loss: 0.0514\n",
            "Epoch 7/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0520 - val_loss: 0.0504\n",
            "Epoch 8/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0474 - val_loss: 0.0430\n",
            "Epoch 9/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0440 - val_loss: 0.0402\n",
            "Epoch 10/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0398 - val_loss: 0.0381\n",
            "Epoch 11/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.0377 - val_loss: 0.0356\n",
            "Epoch 12/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0336 - val_loss: 0.0298\n",
            "Epoch 13/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0296 - val_loss: 0.0293\n",
            "Epoch 14/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0294 - val_loss: 0.0273\n",
            "Epoch 15/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0280 - val_loss: 0.0267\n",
            "Epoch 16/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0271 - val_loss: 0.0255\n",
            "Epoch 17/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0258 - val_loss: 0.0237\n",
            "Epoch 18/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0259 - val_loss: 0.0257\n",
            "Epoch 19/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0224 - val_loss: 0.0231\n",
            "Epoch 20/20\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0212 - val_loss: 0.0197\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n",
            "Threshold: 0.05574732568009123\n",
            "Number of anomalies detected: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = load_sequences_from_csv(\"cheque.csv\")\n",
        "X_train, X_test = train_test_split(sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model more\n",
        "history = model.fit(X_train, X_train, epochs=20, batch_size=32, validation_split=0.2, shuffle=True)\n",
        "\n",
        "# Reconstruction errors\n",
        "X_test_pred = model.predict(X_test)\n",
        "test_loss = np.mean(np.power(X_test - X_test_pred, 2), axis=(1, 2))\n",
        "\n",
        "# Anomaly detection threshold\n",
        "threshold = np.percentile(test_loss, 95)  # Adjust as needed\n",
        "anomalies = test_loss > threshold\n",
        "\n",
        "print(f\"Threshold: {threshold}\")\n",
        "print(f\"Number of anomalies detected: {np.sum(anomalies)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyLbXBtER8KZ",
        "outputId": "112cd6bd-bc1b-49d9-8c36-b3d9ceb24b8e"
      },
      "id": "KyLbXBtER8KZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 4.9758e-04 - val_loss: 4.6399e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - loss: 9.5539e-04 - val_loss: 2.3122e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 18ms/step - loss: 3.6410e-04 - val_loss: 1.6483e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 6.1018e-04 - val_loss: 1.8335e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 19ms/step - loss: 4.4134e-04 - val_loss: 0.0015\n",
            "Epoch 6/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 7.0897e-04 - val_loss: 1.4931e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 2.0021e-04 - val_loss: 2.1210e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 19ms/step - loss: 1.7541e-04 - val_loss: 1.3667e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 19ms/step - loss: 9.3998e-04 - val_loss: 1.3430e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 19ms/step - loss: 2.2210e-04 - val_loss: 1.3322e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 19ms/step - loss: 2.6365e-04 - val_loss: 1.2302e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.8291e-04 - val_loss: 1.2774e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.4762e-04 - val_loss: 1.2379e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 2.1998e-04 - val_loss: 1.1824e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.5576e-04 - val_loss: 1.2333e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.3975e-04 - val_loss: 1.3299e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.8576e-04 - val_loss: 1.1857e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 18ms/step - loss: 1.4027e-04 - val_loss: 1.2159e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 2.4107e-04 - val_loss: 1.1713e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m4086/4086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 18ms/step - loss: 1.3321e-04 - val_loss: 1.4165e-04\n",
            "\u001b[1m1277/1277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step\n",
            "Threshold: 0.00011115491731593637\n",
            "Number of anomalies detected: 2043\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "lstm_test.ipynb",
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}